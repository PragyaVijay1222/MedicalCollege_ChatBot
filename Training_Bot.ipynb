{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09204aba-c597-4dfd-80c3-1ebc97e8885d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n", 
    "from tensorflow.keras.optimizers.legacy import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2680aed2-9aa8-4b8f-99a1-1653672f5595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['Hi'], 'introduction'), (['Hello'], 'introduction'), (['Aap', 'kya', 'kar', 'sakte', 'ho', '?'], 'introduction'), (['Namaste'], 'introduction'), (['Kya', 'aap', 'meri', 'help', 'kar', 'sakte', 'ho', '?'], 'introduction'), (['Main', 'nursing', 'college', 'mein', 'admission', 'lena', 'chahta', 'hoon'], 'admission_interest'), (['Mujhe', 'nursing', 'program', 'ke', 'liye', 'apply', 'karna', 'hai'], 'admission_interest'), (['Admission', 'ke', 'liye', 'kya', 'karna', 'hoga'], 'admission_interest'), (['B.Sc', 'Nursing', 'ka', 'admission', 'chahiye'], 'admission_interest'), (['How', 'can', 'I', 'get', 'admission', 'in', 'nursing', 'college'], 'admission_interest'), (['Haan', 'maine', '12th', 'mein', 'biology', 'padha', 'hai'], 'eligibility_check'), (['Yes', 'I', 'had', 'biology', 'in', 'class', '12'], 'eligibility_check'), (['Mera', '12th', 'mein', 'subject', 'biology', 'tha'], 'eligibility_check'), (['Biology', 'tha', 'mere', 'paas', '12th', 'mein'], 'eligibility_check'), (['Nahi', 'maine', 'biology', 'nahi', 'padha'], 'ineligible_no_biology'), (['Mera', 'subject', 'commerce', 'tha'], 'ineligible_no_biology'), (['Maine', 'science', 'liya', 'tha', 'par', 'biology', 'nahi', 'tha'], 'ineligible_no_biology'), (['No', 'I', 'did', 'not', 'study', 'biology'], 'ineligible_no_biology'), (['B.Sc', 'nursing', 'program', 'ke', 'baare', 'mein', 'batayein'], 'program_details'), (['Course', 'ki', 'details', 'dijiye'], 'program_details'), (['Nursing', 'program', 'ka', 'structure', 'kya', 'hai'], 'program_details'), (['Tell', 'me', 'about', 'B.Sc', 'nursing', 'course'], 'program_details'), (['Fee', 'structure', 'kya', 'hai'], 'fees_info'), (['Is', 'course', 'ki', 'fees', 'kitni', 'hai'], 'fees_info'), (['Kitna', 'kharcha', 'aayega', 'is', 'program', 'ka'], 'fees_info'), (['What', 'is', 'the', 'total', 'fee'], 'fees_info'), (['Hostel', 'ki', 'facilities', 'batao'], 'hostel_training'), (['Accommodation', 'available', 'hai', 'kya'], 'hostel_training'), (['Hospital', 'training', 'hoti', 'hai', 'kya'], 'hostel_training'), (['Hostel', 'aur', 'training', 'ka', 'kya', 'system', 'hai'], 'hostel_training'), (['College', 'kahan', 'hai'], 'college_location'), (['Location', 'batao', 'nursing', 'college', 'ki'], 'college_location'), (['Nursing', 'college', 'Delhi', 'mein', 'hai', 'kya'], 'college_location'), (['Where', 'is', 'your', 'nursing', 'college'], 'college_location'), (['College', 'ka', 'approval', 'kis', 'se', 'hai'], 'recognition'), (['Recognition', 'details', 'kya', 'hain'], 'recognition'), (['Kya', 'college', 'INC', 'se', 'approved', 'hai'], 'recognition'), (['Nursing', 'council', 'ka', 'approval', 'hai', 'kya'], 'recognition'), (['Training', 'kahan', 'hoti', 'hai'], 'clinical_training'), (['Hospital', 'list', 'batao'], 'clinical_training'), (['Clinical', 'training', 'ke', 'centers', 'kaun', 'se', 'hain'], 'clinical_training'), (['Training', 'hospital', 'kaun', 'kaun', 'se', 'hain'], 'clinical_training'), (['Scholarship', 'milti', 'hai', 'kya'], 'scholarship'), (['Financial', 'aid', 'available', 'hai', 'kya'], 'scholarship'), (['Scholarship', 'options', 'kya', 'hain'], 'scholarship'), (['Fee', 'mein', 'koi', 'concession', 'hai', 'kya'], 'scholarship'), (['Seats', 'kitni', 'hain', 'nursing', 'program', 'mein'], 'seats_info'), (['Total', 'kitni', 'seats', 'hain'], 'seats_info'), (['Admission', 'ke', 'liye', 'seats', 'availability'], 'seats_info'), (['Nursing', 'program', 'mein', 'kitne', 'seats', 'hote', 'hain'], 'seats_info'), (['Admission', 'ke', 'liye', 'eligibility', 'kya', 'hai'], 'eligibility'), (['Nursing', 'college', 'ka', 'criteria', 'kya', 'hai'], 'eligibility'), (['Eligibility', 'conditions', 'batao'], 'eligibility'), (['Who', 'can', 'apply', 'for', 'nursing', 'program'], 'eligibility')]\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "intents = json.loads(open('intents.json',encoding='utf-8').read())\n",
    "words=[]\n",
    "classes=[]\n",
    "documents=[]\n",
    "ignore_letters=['?', '!','.',',']\n",
    "\n",
    "for intent in intents['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        word_list = nltk.word_tokenize(pattern)\n",
    "        words.extend(word_list)\n",
    "        documents.append((word_list, intent['tag']))\n",
    "        if intent['tag'] not in classes:\n",
    "            classes.append(intent['tag'])\n",
    "\n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c80bc19e-b8fa-4e3e-ab6c-664603e13650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12', '12th', 'Aap', 'Accommodation', 'Admission', 'B.Sc', 'Biology', 'Clinical', 'College', 'Course', 'Delhi', 'Eligibility', 'Fee', 'Financial', 'Haan', 'Hello', 'Hi', 'Hospital', 'Hostel', 'How', 'I', 'INC', 'Is', 'Kitna', 'Kya', 'Location', 'Main', 'Maine', 'Mera', 'Mujhe', 'Nahi', 'Namaste', 'No', 'Nursing', 'Recognition', 'Scholarship', 'Seats', 'Tell', 'Total', 'Training', 'What', 'Where', 'Who', 'Yes', 'aap', 'aayega', 'about', 'admission', 'aid', 'apply', 'approval', 'approved', 'aur', 'availability', 'available', 'baare', 'batao', 'batayein', 'biology', 'can', 'center', 'chahiye', 'chahta', 'class', 'college', 'commerce', 'concession', 'condition', 'council', 'course', 'criterion', 'detail', 'did', 'dijiye', 'eligibility', 'facility', 'fee', 'for', 'get', 'had', 'hai', 'hain', 'help', 'ho', 'hoga', 'hoon', 'hospital', 'hote', 'hoti', 'in', 'is', 'ka', 'kahan', 'kar', 'karna', 'kaun', 'ke', 'kharcha', 'ki', 'kitne', 'kitni', 'koi', 'kya', 'lena', 'list', 'liya', 'liye', 'maine', 'me', 'mein', 'mere', 'meri', 'milti', 'nahi', 'not', 'nursing', 'option', 'paas', 'padha', 'par', 'program', 'sakte', 'science', 'se', 'seat', 'structure', 'study', 'subject', 'system', 'tha', 'the', 'total', 'training', 'your']\n"
     ]
    }
   ],
   "source": [
    "words = [lemmatizer.lemmatize(word) for word in words if word not in ignore_letters]\n",
    "words = sorted(set(words))\n",
    "\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c5106bf-b879-4499-b065-867157925830",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = sorted(set(classes))\n",
    "pickle.dump(words, open('words.pkl', 'wb'))\n",
    "pickle.dump(classes, open('classes.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f11edae6-d45b-4739-a05f-d4118e36cbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = []\n",
    "output_empty = [0]*len(classes)\n",
    "\n",
    "for document in documents:\n",
    "    bag=[]\n",
    "    word_patterns = document[0]\n",
    "    word_patterns = [lemmatizer.lemmatize(word.lower()) for word in word_patterns]\n",
    "    for word in words:\n",
    "        bag.append(1) if word in word_patterns else bag.append(0)\n",
    "    output_row= list(output_empty)\n",
    "    output_row[classes.index(document[1])]=1\n",
    "    training.append([bag, output_row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9ba89f-aca4-4960-9139-f285943ffa66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "11/11 [==============================] - 1s 5ms/step - loss: 2.6004 - accuracy: 0.1296\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 2.5028 - accuracy: 0.1296\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.4753 - accuracy: 0.1296\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 2.4136 - accuracy: 0.2963\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 2.3572 - accuracy: 0.2963\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 2.3191 - accuracy: 0.2407\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 2.1792 - accuracy: 0.2593\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 2.0770 - accuracy: 0.3519\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 2.0538 - accuracy: 0.4074\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.8431 - accuracy: 0.4815\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.7342 - accuracy: 0.5000\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.5800 - accuracy: 0.6296\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.4374 - accuracy: 0.5741\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.3273 - accuracy: 0.6852\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.2186 - accuracy: 0.6481\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.3028 - accuracy: 0.5556\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1.0223 - accuracy: 0.7593\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.0575 - accuracy: 0.7407\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.1724 - accuracy: 0.5926\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.9146 - accuracy: 0.7037\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.0166 - accuracy: 0.7407\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.8408 - accuracy: 0.7222\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8858 - accuracy: 0.7778\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7385 - accuracy: 0.7593\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6169 - accuracy: 0.8519\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7496 - accuracy: 0.7593\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6181 - accuracy: 0.7963\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4821 - accuracy: 0.8704\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6352 - accuracy: 0.7778\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5817 - accuracy: 0.8704\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6021 - accuracy: 0.8148\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5028 - accuracy: 0.8889\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5115 - accuracy: 0.8889\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4442 - accuracy: 0.8889\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5534 - accuracy: 0.8148\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.3271 - accuracy: 0.9630\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2839 - accuracy: 0.9074\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3265 - accuracy: 0.9259\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.3689 - accuracy: 0.8704\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1952 - accuracy: 0.9444\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.8519\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.3470 - accuracy: 0.9259\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3626 - accuracy: 0.8889\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2773 - accuracy: 0.9259\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3797 - accuracy: 0.9074\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4109 - accuracy: 0.8148\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2544 - accuracy: 0.9259\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2961 - accuracy: 0.9630\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3431 - accuracy: 0.8889\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3310 - accuracy: 0.9259\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2227 - accuracy: 0.9630\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2133 - accuracy: 0.9444\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3458 - accuracy: 0.9259\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2682 - accuracy: 0.9259\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1977 - accuracy: 0.9444\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1284 - accuracy: 1.0000\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1691 - accuracy: 0.9630\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2265 - accuracy: 0.9074\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3061 - accuracy: 0.9259\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2380 - accuracy: 0.9444\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1545 - accuracy: 0.9815\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2004 - accuracy: 0.9259\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1648 - accuracy: 0.9815\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2034 - accuracy: 0.9444\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2082 - accuracy: 0.9444\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2113 - accuracy: 0.9259\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1565 - accuracy: 0.9630\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1812 - accuracy: 0.9444\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2137 - accuracy: 0.9259\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1317 - accuracy: 0.9815\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1342 - accuracy: 0.9815\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1151 - accuracy: 0.9815\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1536 - accuracy: 0.9630\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0421 - accuracy: 1.0000\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2200 - accuracy: 0.9630\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1749 - accuracy: 0.9444\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1399 - accuracy: 0.9630\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0783 - accuracy: 1.0000\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1935 - accuracy: 0.9815\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1081 - accuracy: 0.9630\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1124 - accuracy: 0.9815\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1477 - accuracy: 0.9815\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1129 - accuracy: 0.9630\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1026 - accuracy: 0.9630\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1150 - accuracy: 0.9630\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0834 - accuracy: 1.0000\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1767 - accuracy: 0.9444\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1071 - accuracy: 0.9630\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1168 - accuracy: 0.9259\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1156 - accuracy: 0.9444\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2115 - accuracy: 0.9259\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1878 - accuracy: 0.9444\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0236 - accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1103 - accuracy: 0.9444\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0998 - accuracy: 0.9630\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2513 - accuracy: 0.9444\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0544 - accuracy: 1.0000\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0704 - accuracy: 0.9815\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0860 - accuracy: 0.9815\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0361 - accuracy: 0.9815\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1071 - accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0671 - accuracy: 0.9815\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0397 - accuracy: 1.0000\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1945 - accuracy: 0.9444\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0386 - accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0449 - accuracy: 0.9815\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1042 - accuracy: 0.9630\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0882 - accuracy: 0.9630\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0865 - accuracy: 0.9815\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0645 - accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0858 - accuracy: 0.9815\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1380 - accuracy: 0.9630\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1219 - accuracy: 0.9630\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0657 - accuracy: 0.9815\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0910 - accuracy: 0.9815\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0720 - accuracy: 0.9815\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0440 - accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0476 - accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0604 - accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0689 - accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0678 - accuracy: 0.9815\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0646 - accuracy: 0.9630\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0685 - accuracy: 0.9815\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0711 - accuracy: 0.9815\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0378 - accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0673 - accuracy: 0.9815\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0187 - accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0892 - accuracy: 0.9444\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0524 - accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0379 - accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0386 - accuracy: 0.9815\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0595 - accuracy: 0.9815\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0600 - accuracy: 0.9815\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0450 - accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0412 - accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0844 - accuracy: 0.9815\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0968 - accuracy: 0.9815\n",
      "Epoch 138/200\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.0067 - accuracy: 1.0000"
     ]
    }
   ],
   "source": [
    "random.shuffle(training)\n",
    "training = np.array(training, dtype=object)\n",
    "\n",
    "train_x = list(training[:, 0])\n",
    "train_y = list(training[:, 1])\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(len(train_x[0]),), activation='relu'))\n",
    "model.add(Dropout(0.5))  \n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(train_y[0]), activation='softmax'))\n",
    "\n",
    "sgd = SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "hist = model.fit(np.array(train_x), np.array(train_y), epochs=200, batch_size =5, verbose=1)\n",
    "\n",
    "model.save('chatbot_model.h5', hist)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e1e756-8d27-42cf-a6f4-a5f82fa1878c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (chatbot_env)",
   "language": "python",
   "name": "chatbot_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
